---
title: SBFT'24 Keynotes
layout: default
---
<div class="col-md-8 ml-auto mr-auto text-left">

  <div class="section section-team text-left">
    <div class="container">
      <h1 class="title">Keynote Talks</h1>
      <div class="team">
        <div class="row">
          <div class="team-player">
            <img src="/img/caroline_lemieux.png" alt="Thumbnail Image"
              class="rounded-circle img-fluid img-raised profile-picture">
            <h4 class="title">Caroline Lemieux</h4>
            <p class="text-secondary">Department of Computer Science, University of British Columbia
              </p>
            
            <h5 class="text-primary">The Power of Fuzzing and Large Language Models</h5>
            <!-- <p><a href="https://www.slideshare.net/briand_lionel/revisiting-the-notion-of-diversity-in-software-testing" target="_blank" class="fa fa-person-chalkboard"> Slides</a></p> -->
            <!-- <p><iframe width="100%" height="315" src="https://www.youtube.com/embed/EF13eiidhA0?start=9932" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p> -->
            <p class="text-justify">
              <strong>Abstract</strong>:
              Feedback-directed fuzzing (a.k.a. coverage-guided or grey-box fuzzing) algorithms and their efficient implementation have shown themselves to be a 
              force in the field of automated testing and bug discovery. These algorithms do great at exploring search spaces through mutation, when each evaluation 
              run is cheap. Large language models have emerged as a force in the generation of both natural language and code, showing promise for search tasks over 
              these spaces. This keynote will cover projects that show the power of feedback-directed-fuzzing on its own, and how large language models can be used most 
              effectively in conjunction with and complement to automated testing techniques.
            </p>
            <!--
            <p class="text-justify">
              <strong>Biography</strong>: Lionel C. Briand is professor of software engineering and has shared
              appointments between (1) The University of Ottawa, Canada and (2) The SnT centre for Security,
              Reliability, and Trust, University of Luxembourg. In collaboration with colleagues, over 25 years, he
              has run many collaborative research projects with companies in the automotive, satellite, aeropsace,
              energy, financial, and legal domains. Lionel has held various engineering, academic, and leading
              positions in six countries. He was one of the founders of the ICST conference (IEEE Int. Conf. on
              Software Testing, Verification, and Validation, a CORE A event) and its first general chair. He was also
              EiC of Empirical Software Engineering (Springer) for 13 years and led, in collaboration with first
              Victor Basili and then Tom Zimmermann, the journal to the top tier of the very best publication venues
              in software engineering.
              <br />
              Lionel was elevated to the grades of IEEE Fellow and ACM Fellow for his work on software testing and
              verification. He was granted the IEEE Computer Society Harlan Mills award, the ACM SIGSOFT outstanding
              research award, and the IEEE Reliability Society engineer-of-the-year award, respectively in 2012, 2022,
              and 2013. He received an ERC Advanced grant in 2016 — on the topic of modelling and testing
              cyber-physical systems — which is the most prestigious individual research award in the European Union.
              He currently holds a Canada Research Chair (Tier 1) on "Intelligent Software Dependability and
              Compliance". His research interests include: software testing and verification, applications of AI in
              software engineering, model-driven software development, requirements engineering, and empirical
              software engineering.
            </p>-->
          </div>
        </div>
        <div class="row">
          <div class="team-player">
            <img src="/img/gfraser.png" alt="Thumbnail Image"
              class="rounded-circle img-fluid img-raised profile-picture">
            <h4 class="title">Gordon Fraser </h4>
            <p class="text-secondary">Faculty of Computer Science and Mathematics, University of Passau</p>
            <h5 class="text-primary">Search-based Testing and Analysis for Block-Based Learners’ Programs</h5>
            <!-- <p><iframe width="100%" height="315" src="https://www.youtube.com/embed/EF13eiidhA0?start=571" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p> -->
            <p class="text-justify">
              <strong>Abstract</strong>:
              Programming is increasingly taught using dedicated block-based programming environments such as Scratch. 
              While the use of blocks instead of text prevents syntax errors, learners can still make semantic mistakes, 
              implying a need for feedback and help. Professional programmers can receive such support from efficient 
              program analyses built into their IDEs, but block-based programming environments offer no such support. 
              In this talk, I will describe some of our efforts to remedy this issue, which are based on search-based 
              testing at the core. The colourful and small nature of learners’ programs is deceiving, as the game-like, 
              highly concurrent and event-driven nature of the programs poses unique challenges for these analyses.
            </p>
            <!-- <p class="text-justify">
              <strong>Biography</strong>: Jane Cleland-Huang is the Frank M. Freimann Professor of Computer Science
              Chair and Department Chair of Computer Science and Engineering at the University of Notre Dame. Her
              research interests focus on Requirements Engineering, Software and Systems Traceability, and Safety
              Assurance for Cyber-Physical Systems (CPS). She is the Project Lead on the DroneResponse project which
              was initially developed as a research platform for supporting Software Engineering research in
              multi-agent CPS, but is now the core platform for a commercial system for deploying small Unmanned
              Aerial Systems (sUAS) in Emergency Response scenarios. Jane has served as Program Chair for several
              conferences including the IEEE Requirements Engineering Conference (2010), ESEC/FSE (2014), ICSE (2020),
              CAIN (2022), and SPLC (2022). She has previously served as Associate Editor of IEEE Transactions on
              Software Engineering and on the IEEE Software editorial board, and currently serves as Chair of IFIP 2.9
              Working group on Requirements Engineering, and on the Editorial Boards for Communications of the ACM abd
              Springer Verlag Requirements Engineering journal.

              <br />

              Along with members of her research group she has been the recipient of seven ACM SIGSOFT Distinguished
              Paper awards, and the Mannfred Paul award for Excellence in Software Theory and Practice. Jane is
              committed to supporting a diverse, equitable, and inclusive community of Software Engineering
              researchers and envisions a future in which our research community is truly reflective of the population
              around us. She is also passionate about impacting the world in a positive way through technology
              transfer that takes research into practice, and as a result is currently engaged in two spin-off
              companies – DroneResponse and SAFA.”
            </p>-->
          </div>
        </div>
        <div class="row">
          <div class="team-player">
            <img src="/img/fasol-2966522-small.gif" alt="Thumbnail Image"
              class="rounded-circle img-fluid img-raised profile-picture">
            <h4 class="title">Anna Rita Fasolino</h4>
            <p class="text-secondary">University of Naples Federico II, Italy</p>
            <h5 class="text-primary">Beyond the Class: A look into current trends in software testing education</h5>
            <!-- <p><iframe width="100%" height="315" src="https://www.youtube.com/embed/EF13eiidhA0?start=571" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p> -->
            <p class="text-justify">
              <strong>Abstract</strong>:
              Software testing is indispensable in software development, yet often overlooked, contributing to a shortage of expertise in the software industry. 
              Despite efforts to improve teaching approaches at the university level, challenges persist, particularly in bridging the gap between theory and 
              practice and better preparing students for their future careers.
              This talk will provide a closer look at how software testing is taught at the academic level, considering the perspectives of students and teachers. 
              I will describe the most common challenges that students experience when taking a software testing course.
              Then, I give voice to teachers, reporting the approaches they usually adopt in software testing courses and the challenges they face. 
              Emerging initiatives like gamification and challenge-based learning are potential solutions to fill the gaps between the teachers’ efforts and students’ needs.
            </p>
            <!-- <p class="text-justify">
              <strong>Biography</strong>: Jane Cleland-Huang is the Frank M. Freimann Professor of Computer Science
              Chair and Department Chair of Computer Science and Engineering at the University of Notre Dame. Her
              research interests focus on Requirements Engineering, Software and Systems Traceability, and Safety
              Assurance for Cyber-Physical Systems (CPS). She is the Project Lead on the DroneResponse project which
              was initially developed as a research platform for supporting Software Engineering research in
              multi-agent CPS, but is now the core platform for a commercial system for deploying small Unmanned
              Aerial Systems (sUAS) in Emergency Response scenarios. Jane has served as Program Chair for several
              conferences including the IEEE Requirements Engineering Conference (2010), ESEC/FSE (2014), ICSE (2020),
              CAIN (2022), and SPLC (2022). She has previously served as Associate Editor of IEEE Transactions on
              Software Engineering and on the IEEE Software editorial board, and currently serves as Chair of IFIP 2.9
              Working group on Requirements Engineering, and on the Editorial Boards for Communications of the ACM abd
              Springer Verlag Requirements Engineering journal.

              <br />

              Along with members of her research group she has been the recipient of seven ACM SIGSOFT Distinguished
              Paper awards, and the Mannfred Paul award for Excellence in Software Theory and Practice. Jane is
              committed to supporting a diverse, equitable, and inclusive community of Software Engineering
              researchers and envisions a future in which our research community is truly reflective of the population
              around us. She is also passionate about impacting the world in a positive way through technology
              transfer that takes research into practice, and as a result is currently engaged in two spin-off
              companies – DroneResponse and SAFA.”
            </p>-->
          </div>
        </div>
      </div>
    </div>
  </div>
</div>